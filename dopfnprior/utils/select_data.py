from typing import Dict, Optional, Tuple
from copy import deepcopy
import torch
import networkx as nx


def select_features(data: Dict[int, torch.Tensor],
                    graph: nx.DiGraph,
                    dropout_prob: float,
                    generator: Optional[torch.Generator]
                    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, nx.DiGraph]:
    """
    Sample train and test tensors from data generated by an SCM. We write
        B for the batch dimension,
        N for the number of data points (rows) in each table,
        F for the number of features,
        D_i for the embedding dimension at node i.
            
    Modify `graph` in place by renaming its nodes and marking deleted nodes.
        
    Parameters:
    -----------
    data : dict
        The value at key i is a tensor of shape (B, N, D_i).
    graph : nx.DiGraph
        The DAG using which `data` sampled.
    dropout_prob : float
        The probability to drop any given feature.
            
    Returns
    -------
    X : tensor of shape (B, N, F)
        The features of the generated data batch.
    y : tensor of shape (B, N, 1)
        The targets of the generated data batch.
    adjacency_matrix : tensor of shape (F, F)
        The adjacency matrix of `graph`.
    graph : nx.DiGraph
        The graph underlying the nodes corresponding to `X` and `y`.
    """
    # select target node
    nodes = list(graph.nodes())
    connected_nodes = [v for v in nodes if len(list(graph.predecessors(v))) > 0 or len(list(graph.successors(v))) > 0]
    target_node_idx = int(torch.randint(0, len(connected_nodes), (1,), generator=generator))
    target_node = connected_nodes[target_node_idx]
    target_values = data[target_node][:, :, 0]
    renaming = {target_node: "y"}
        
    # treat non-target features
    nodes.remove(target_node)
    kept = []
    dropped = []
    new_idx = 0
    new_hidden_idx = 0
    for i, v in enumerate(nodes):
        # make sure to keep at least two nodes, overriding the sampling if necessary
        if torch.rand(1, generator=generator) > dropout_prob or (len(kept) < 2 and i >= len(nodes) - 2):
            kept.append(v)
            renaming[v] = f"x{new_idx}"
            new_idx += 1
        else:
            dropped.append(v)
            renaming[v] = f"u{new_hidden_idx}"
            new_hidden_idx += 1
            graph.nodes[v]["dropped"] = True
        
    feature_values = torch.cat(list(data[v] for v in kept), dim=2)
        
    # randomly switch signs
    B, N, F = feature_values.shape
    sign_x = torch.randint(0, 2, (B, 1, F), generator=generator, dtype=torch.float32) * 2 - 1
    feature_values *= sign_x
    sign_y = torch.randint(0, 2, (B, 1), generator=generator, dtype=torch.float32) * 2 - 1
    target_values *= sign_y
        
    # modify the graph
    new_graph = deepcopy(graph)
    new_graph.remove_nodes_from(dropped)
    kept.append(target_node)
    for v in dropped:
        preds = [u for u in graph.predecessors(v) if u in kept]
        succs = [u for u in graph.successors(v) if u in kept]
        for u1 in preds:
            for u2 in succs:
                if u1 != u2 and not graph.has_edge(u1, u2):
                    new_graph.add_edge(u1, u2, contracted=True)
    adjacency_matrix = torch.from_numpy(nx.to_numpy_array(new_graph, kept)).to(feature_values.dtype)
    nx.relabel_nodes(graph, renaming, copy=False)
    nx.relabel_nodes(new_graph, renaming, copy=False)
        
    # shuffle data
    perm_rows = torch.randperm(N, device=feature_values.device, generator=generator)
    X = feature_values[:, perm_rows, :]
    y = target_values[:, perm_rows]
        
    return X, y, adjacency_matrix, new_graph